{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1199344,"sourceType":"datasetVersion","datasetId":683366}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Dataset","metadata":{}},{"cell_type":"code","source":"import os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-13T17:11:51.378711Z","iopub.execute_input":"2024-08-13T17:11:51.379240Z","iopub.status.idle":"2024-08-13T17:11:51.389762Z","shell.execute_reply.started":"2024-08-13T17:11:51.379210Z","shell.execute_reply":"2024-08-13T17:11:51.388915Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def extract():\n    text = ''\n    path = '/kaggle/input/marvel-cinematic-universe-dialogue-dataset'\n    for file in os.listdir(path):\n        path_file = os.path.join(path + '/', file)\n        with open(path_file, 'r', errors= 'ignore') as f:\n            text += f.read()\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:51.391095Z","iopub.execute_input":"2024-08-13T17:11:51.391394Z","iopub.status.idle":"2024-08-13T17:11:51.400286Z","shell.execute_reply.started":"2024-08-13T17:11:51.391371Z","shell.execute_reply":"2024-08-13T17:11:51.399544Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"text = extract()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:51.402067Z","iopub.execute_input":"2024-08-13T17:11:51.402761Z","iopub.status.idle":"2024-08-13T17:11:51.534659Z","shell.execute_reply.started":"2024-08-13T17:11:51.402737Z","shell.execute_reply":"2024-08-13T17:11:51.533885Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"text[:100]","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:51.535665Z","iopub.execute_input":"2024-08-13T17:11:51.535918Z","iopub.status.idle":"2024-08-13T17:11:51.542400Z","shell.execute_reply.started":"2024-08-13T17:11:51.535896Z","shell.execute_reply":"2024-08-13T17:11:51.541502Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'(BUCKY SCREAMING)\\n(CONTINUES SCREAMING)\\n- (KARPOV SPEAKING RUSSIAN) - (PANTING)\\nLonging\\nRusted\\nSeven'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Text Processing","metadata":{}},{"cell_type":"code","source":"class Preprocess():\n    def __init__(self, text):\n        super().__init__()\n        self.text = text\n        \n    def create_vocab(self):\n        vocab = sorted(list(set(self.text)))\n        self.stoi = {s: i for i, s in enumerate(vocab)}\n        self.itos = {i: s for s, i in self.stoi.items()}\n        return vocab, len(vocab), self.stoi, self.itos\n    \n    def encode(self, string):\n        return [self.stoi[char] for char in string]\n    \n    def decode(self, array):\n        return ''.join(self.itos[idx] for idx in array)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:51.544218Z","iopub.execute_input":"2024-08-13T17:11:51.544475Z","iopub.status.idle":"2024-08-13T17:11:51.552298Z","shell.execute_reply.started":"2024-08-13T17:11:51.544453Z","shell.execute_reply":"2024-08-13T17:11:51.551376Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"text_processor = Preprocess(text)\nvocab, vocab_size, stoi, itos = text_processor.create_vocab()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:51.553349Z","iopub.execute_input":"2024-08-13T17:11:51.553603Z","iopub.status.idle":"2024-08-13T17:11:51.578958Z","shell.execute_reply.started":"2024-08-13T17:11:51.553577Z","shell.execute_reply":"2024-08-13T17:11:51.578125Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(text_processor.encode('hello'))\ntext_processor.decode(text_processor.encode('hello'))","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:51.579998Z","iopub.execute_input":"2024-08-13T17:11:51.580308Z","iopub.status.idle":"2024-08-13T17:11:51.591478Z","shell.execute_reply.started":"2024-08-13T17:11:51.580278Z","shell.execute_reply":"2024-08-13T17:11:51.590566Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[61, 58, 65, 65, 68]\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'hello'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Set Device","metadata":{}},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:51.592466Z","iopub.execute_input":"2024-08-13T17:11:51.592727Z","iopub.status.idle":"2024-08-13T17:11:55.274197Z","shell.execute_reply.started":"2024-08-13T17:11:51.592705Z","shell.execute_reply":"2024-08-13T17:11:55.273268Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.275444Z","iopub.execute_input":"2024-08-13T17:11:55.275981Z","iopub.status.idle":"2024-08-13T17:11:55.313229Z","shell.execute_reply.started":"2024-08-13T17:11:55.275948Z","shell.execute_reply":"2024-08-13T17:11:55.311916Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Split Dataset","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.316315Z","iopub.execute_input":"2024-08-13T17:11:55.316624Z","iopub.status.idle":"2024-08-13T17:11:55.326429Z","shell.execute_reply.started":"2024-08-13T17:11:55.316590Z","shell.execute_reply":"2024-08-13T17:11:55.325504Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data = torch.tensor(text_processor.encode(text), dtype = torch.long)\ndata[:50], len(data)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.327473Z","iopub.execute_input":"2024-08-13T17:11:55.327813Z","iopub.status.idle":"2024-08-13T17:11:55.689110Z","shell.execute_reply.started":"2024-08-13T17:11:55.327783Z","shell.execute_reply":"2024-08-13T17:11:55.687867Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(tensor([ 8, 29, 48, 30, 38, 52,  1, 46, 30, 45, 32, 28, 40, 36, 41, 34,  9,  0,\n          8, 30, 42, 41, 47, 36, 41, 48, 32, 46,  1, 46, 30, 45, 32, 28, 40, 36,\n         41, 34,  9,  0, 12,  1,  8, 38, 28, 45, 43, 42, 49,  1]),\n 1147310)"},"metadata":{}}]},{"cell_type":"code","source":"n = int(0.8 * len(data))\ntrain = data[:n]\nval = data[n:]\nlen(train), len(val)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.690424Z","iopub.execute_input":"2024-08-13T17:11:55.690859Z","iopub.status.idle":"2024-08-13T17:11:55.701494Z","shell.execute_reply.started":"2024-08-13T17:11:55.690819Z","shell.execute_reply":"2024-08-13T17:11:55.700388Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(917848, 229462)"},"metadata":{}}]},{"cell_type":"code","source":"def split(type):\n    data = train if type == 'train' else val\n    idx = torch.randint(len(data) - block_size, (batch_size, ))\n    X = torch.stack([data[i: i + block_size] for i in idx])\n    y = torch.stack([data[i + 1: i + block_size + 1] for i in idx])\n    X, y = X.to(device), y.to(device)\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.703302Z","iopub.execute_input":"2024-08-13T17:11:55.704318Z","iopub.status.idle":"2024-08-13T17:11:55.718333Z","shell.execute_reply.started":"2024-08-13T17:11:55.704273Z","shell.execute_reply":"2024-08-13T17:11:55.717077Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"batch_size = 64 \nblock_size = 256 \nmax_iters = 5000\neval_interval = 500\nlearning_rate = 1e-3\neval_iters = 200\nn_embd = 384\nn_head = 6\nn_layer = 6\ndropout = 0.2","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.720655Z","iopub.execute_input":"2024-08-13T17:11:55.722549Z","iopub.status.idle":"2024-08-13T17:11:55.735737Z","shell.execute_reply.started":"2024-08-13T17:11:55.722493Z","shell.execute_reply":"2024-08-13T17:11:55.730445Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"Xtr, ytr = split('train')\nXtr.shape, ytr.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.737896Z","iopub.execute_input":"2024-08-13T17:11:55.739215Z","iopub.status.idle":"2024-08-13T17:11:55.934837Z","shell.execute_reply.started":"2024-08-13T17:11:55.739172Z","shell.execute_reply":"2024-08-13T17:11:55.933853Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(torch.Size([64, 256]), torch.Size([64, 256]))"},"metadata":{}}]},{"cell_type":"markdown","source":"# Define Error List","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.936237Z","iopub.execute_input":"2024-08-13T17:11:55.936593Z","iopub.status.idle":"2024-08-13T17:11:55.941703Z","shell.execute_reply.started":"2024-08-13T17:11:55.936561Z","shell.execute_reply":"2024-08-13T17:11:55.940580Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for splits in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = split(splits)\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[splits] = losses.mean()\n    model.train()\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.943088Z","iopub.execute_input":"2024-08-13T17:11:55.943710Z","iopub.status.idle":"2024-08-13T17:11:55.953174Z","shell.execute_reply.started":"2024-08-13T17:11:55.943676Z","shell.execute_reply":"2024-08-13T17:11:55.952279Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        self.key = nn.Linear(n_embd, head_size, bias=False)\n        self.query = nn.Linear(n_embd, head_size, bias=False)\n        self.value = nn.Linear(n_embd, head_size, bias=False)\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        B,T,C = x.shape\n        k = self.key(x)   # (B,T,C)\n        q = self.query(x) # (B,T,C)\n        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n        wei = F.softmax(wei, dim=-1) # (B, T, T)\n        wei = self.dropout(wei)\n        v = self.value(x) # (B,T,C)\n        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.954303Z","iopub.execute_input":"2024-08-13T17:11:55.954717Z","iopub.status.idle":"2024-08-13T17:11:55.968721Z","shell.execute_reply.started":"2024-08-13T17:11:55.954692Z","shell.execute_reply":"2024-08-13T17:11:55.967558Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.proj = nn.Linear(n_embd, n_embd)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.969920Z","iopub.execute_input":"2024-08-13T17:11:55.970207Z","iopub.status.idle":"2024-08-13T17:11:55.979490Z","shell.execute_reply.started":"2024-08-13T17:11:55.970183Z","shell.execute_reply":"2024-08-13T17:11:55.978656Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class FeedFoward(nn.Module):\n    def __init__(self, n_embd):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_embd, 4 * n_embd),\n            nn.ReLU(),\n            nn.Linear(4 * n_embd, n_embd),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.980545Z","iopub.execute_input":"2024-08-13T17:11:55.981292Z","iopub.status.idle":"2024-08-13T17:11:55.990236Z","shell.execute_reply.started":"2024-08-13T17:11:55.981267Z","shell.execute_reply":"2024-08-13T17:11:55.989426Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, n_embd, n_head):\n        super().__init__()\n        head_size = n_embd // n_head\n        self.sa = MultiHeadAttention(n_head, head_size)\n        self.ffwd = FeedFoward(n_embd)\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n\n    def forward(self, x):\n        x = x + self.sa(self.ln1(x))\n        x = x + self.ffwd(self.ln2(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:55.991307Z","iopub.execute_input":"2024-08-13T17:11:55.991677Z","iopub.status.idle":"2024-08-13T17:11:56.002076Z","shell.execute_reply.started":"2024-08-13T17:11:55.991647Z","shell.execute_reply":"2024-08-13T17:11:56.001160Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class BigramLanguageModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n        self.lm_head = nn.Linear(n_embd, vocab_size)\n\n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n        x = tok_emb + pos_emb # (B,T,C)\n        x = self.blocks(x) # (B,T,C)\n        x = self.ln_f(x) # (B,T,C)\n        logits = self.lm_head(x) # (B,T,vocab_size)\n\n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        for _ in range(max_new_tokens):\n            idx_cond = idx[:, -block_size:]\n            logits, loss = self(idx_cond)\n            logits = logits[:, -1, :] # becomes (B, C)\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:56.003165Z","iopub.execute_input":"2024-08-13T17:11:56.003604Z","iopub.status.idle":"2024-08-13T17:11:56.017348Z","shell.execute_reply.started":"2024-08-13T17:11:56.003573Z","shell.execute_reply":"2024-08-13T17:11:56.016443Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = BigramLanguageModel()\nm = model.to(device)\nprint(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:56.018447Z","iopub.execute_input":"2024-08-13T17:11:56.018779Z","iopub.status.idle":"2024-08-13T17:11:56.199865Z","shell.execute_reply.started":"2024-08-13T17:11:56.018744Z","shell.execute_reply":"2024-08-13T17:11:56.198770Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"10.80354 M parameters\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n\nfor iter in range(max_iters):\n    if iter % eval_interval == 0 or iter == max_iters - 1:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n    xb, yb = split('train')\n    logits, loss = model(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:11:56.201258Z","iopub.execute_input":"2024-08-13T17:11:56.201649Z","iopub.status.idle":"2024-08-13T17:41:24.563019Z","shell.execute_reply.started":"2024-08-13T17:11:56.201594Z","shell.execute_reply":"2024-08-13T17:41:24.562034Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"step 0: train loss 4.5380, val loss 4.5450\nstep 500: train loss 1.6741, val loss 1.7039\nstep 1000: train loss 1.3356, val loss 1.4401\nstep 1500: train loss 1.1957, val loss 1.3666\nstep 2000: train loss 1.1067, val loss 1.3545\nstep 2500: train loss 1.0325, val loss 1.3539\nstep 3000: train loss 0.9557, val loss 1.3798\nstep 3500: train loss 0.8865, val loss 1.4070\nstep 4000: train loss 0.8166, val loss 1.4502\nstep 4500: train loss 0.7514, val loss 1.4761\nstep 4999: train loss 0.6912, val loss 1.5150\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Generate Text","metadata":{}},{"cell_type":"code","source":"def generate(num_words):\n    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n    print(text_processor.decode(m.generate(context, max_new_tokens = num_words)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:41:24.567773Z","iopub.execute_input":"2024-08-13T17:41:24.568182Z","iopub.status.idle":"2024-08-13T17:41:24.573461Z","shell.execute_reply.started":"2024-08-13T17:41:24.568156Z","shell.execute_reply":"2024-08-13T17:41:24.572641Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"generate(2000)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:41:24.574491Z","iopub.execute_input":"2024-08-13T17:41:24.574834Z","iopub.status.idle":"2024-08-13T17:41:59.059509Z","shell.execute_reply.started":"2024-08-13T17:41:24.574803Z","shell.execute_reply":"2024-08-13T17:41:59.058583Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"\nAre you gonna be all a fight? It's metal fun.\n- Still you are gonna spak it again? - Go.\nLook, what's this guy who has been? I'm trying to kill you.\nWhere do you the past does think and you call this people could be before it hasn't.\nI know you don't know you'll even.\nI don't even know what you're because I know who you ammule.\nI'm in trouble. She's provided like her.\nShe's spying to find the relies. But you don't even know what's it doing.\nJust an earth in a hand.\nI'm the froad of the Bifrost thing will be dead.\nOkay. Emerge design.\nWe have a plan. Well, But you knew didn't have you anything\nby with now, I'm happy careing this thing.\nWanda, I thought I was gonna have that? Peter's happening.\nBig side, Scott.\nI'm not like an even threat further said you'd know anyone nothing.\nI'm gonna gonna stop you.\nI'm honey. I'm very dying on.\nNo, this is gonna work...\nNo, no.\nSarrifying.\nI don't know, Scott.\nAnd you're not gonna be a what I'm not.\nI love American. Hey.\nHey, Luis. I'm so sorry.\nI said I refear myself human for two weeks.\nI build hear, Loki, but he... wait for your...\nWhat do you see her? You're many optioned?\nLook at me nor long at me.\nIt's beautiful. Hard to meet Language didn't Thor.\nI shouldn't. I'm sure his anut.\nNo, it's necking is nothing!\nThen get down!\nI won't at him!\nCaught human means we biggered at Bit of the Covergence one is your gun.\nBetter this thing. So, if you will tear the world, I work with a guy with Monic.\nI'm not sure what we have...\nSorry.\nSorry.\nIf we couldn't control it before that thing didn't work in Sorth and sister.\nTony, I'm freaking for right.\nYou're almore to lose me that now.\nYou can changed your enemies swing a thing.\nYou're gonna have to consuse me else me.\nIf you're gonna give it, Europe at you.\n(ALNT CEARING)\n(BRAKA PPRACKING RUMDIT: Stank to go.\n(GURMUS Barnes work, isn't out.\nBuckles were in a gride.\nI toleboard find to beying valuation.\nI must've never met tasted drivisel recon.\nYou don't know that to rusk at your partness\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}}]}