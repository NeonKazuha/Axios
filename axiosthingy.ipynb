{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1199344,"sourceType":"datasetVersion","datasetId":683366}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Dataset","metadata":{}},{"cell_type":"code","source":"import os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-18T17:55:24.165333Z","iopub.execute_input":"2024-08-18T17:55:24.166242Z","iopub.status.idle":"2024-08-18T17:55:24.170428Z","shell.execute_reply.started":"2024-08-18T17:55:24.166198Z","shell.execute_reply":"2024-08-18T17:55:24.169506Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def extract():\n    text = ''\n    path = '/kaggle/input/marvel-cinematic-universe-dialogue-dataset'\n    for file in os.listdir(path):\n        path_file = os.path.join(path + '/', file)\n        with open(path_file, 'r', errors= 'ignore') as f:\n            text += f.read()\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.172092Z","iopub.execute_input":"2024-08-18T17:55:24.172343Z","iopub.status.idle":"2024-08-18T17:55:24.181464Z","shell.execute_reply.started":"2024-08-18T17:55:24.172321Z","shell.execute_reply":"2024-08-18T17:55:24.180599Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"text = extract()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.182484Z","iopub.execute_input":"2024-08-18T17:55:24.184286Z","iopub.status.idle":"2024-08-18T17:55:24.242630Z","shell.execute_reply.started":"2024-08-18T17:55:24.184261Z","shell.execute_reply":"2024-08-18T17:55:24.241787Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"text[:100]","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.244834Z","iopub.execute_input":"2024-08-18T17:55:24.245089Z","iopub.status.idle":"2024-08-18T17:55:24.250481Z","shell.execute_reply.started":"2024-08-18T17:55:24.245067Z","shell.execute_reply":"2024-08-18T17:55:24.249615Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"'(BUCKY SCREAMING)\\n(CONTINUES SCREAMING)\\n- (KARPOV SPEAKING RUSSIAN) - (PANTING)\\nLonging\\nRusted\\nSeven'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Text Processing","metadata":{}},{"cell_type":"code","source":"class Preprocess():\n    def __init__(self, text):\n        super().__init__()\n        self.text = text\n        \n    def create_vocab(self):\n        vocab = sorted(list(set(self.text)))\n        self.stoi = {s: i for i, s in enumerate(vocab)}\n        self.itos = {i: s for s, i in self.stoi.items()}\n        return vocab, len(vocab), self.stoi, self.itos\n    \n    def encode(self, string):\n        return [self.stoi[char] for char in string]\n    \n    def decode(self, array):\n        return ''.join(self.itos[idx] for idx in array)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.251315Z","iopub.execute_input":"2024-08-18T17:55:24.251846Z","iopub.status.idle":"2024-08-18T17:55:24.260921Z","shell.execute_reply.started":"2024-08-18T17:55:24.251822Z","shell.execute_reply":"2024-08-18T17:55:24.260129Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"text_processor = Preprocess(text)\nvocab, vocab_size, stoi, itos = text_processor.create_vocab()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.262011Z","iopub.execute_input":"2024-08-18T17:55:24.262280Z","iopub.status.idle":"2024-08-18T17:55:24.288530Z","shell.execute_reply.started":"2024-08-18T17:55:24.262258Z","shell.execute_reply":"2024-08-18T17:55:24.287549Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print(text_processor.encode('hello'))\ntext_processor.decode(text_processor.encode('hello'))","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.289710Z","iopub.execute_input":"2024-08-18T17:55:24.290067Z","iopub.status.idle":"2024-08-18T17:55:24.302090Z","shell.execute_reply.started":"2024-08-18T17:55:24.290036Z","shell.execute_reply":"2024-08-18T17:55:24.301138Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"[61, 58, 65, 65, 68]\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'hello'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Set Device","metadata":{}},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.303399Z","iopub.execute_input":"2024-08-18T17:55:24.303694Z","iopub.status.idle":"2024-08-18T17:55:24.310270Z","shell.execute_reply.started":"2024-08-18T17:55:24.303648Z","shell.execute_reply":"2024-08-18T17:55:24.309482Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.313490Z","iopub.execute_input":"2024-08-18T17:55:24.313795Z","iopub.status.idle":"2024-08-18T17:55:24.323638Z","shell.execute_reply.started":"2024-08-18T17:55:24.313764Z","shell.execute_reply":"2024-08-18T17:55:24.322795Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Split Dataset","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.324493Z","iopub.execute_input":"2024-08-18T17:55:24.324777Z","iopub.status.idle":"2024-08-18T17:55:24.333104Z","shell.execute_reply.started":"2024-08-18T17:55:24.324705Z","shell.execute_reply":"2024-08-18T17:55:24.332271Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"data = torch.tensor(text_processor.encode(text), dtype = torch.long)\ndata[:50], len(data)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.333940Z","iopub.execute_input":"2024-08-18T17:55:24.334184Z","iopub.status.idle":"2024-08-18T17:55:24.620032Z","shell.execute_reply.started":"2024-08-18T17:55:24.334162Z","shell.execute_reply":"2024-08-18T17:55:24.619036Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(tensor([ 8, 29, 48, 30, 38, 52,  1, 46, 30, 45, 32, 28, 40, 36, 41, 34,  9,  0,\n          8, 30, 42, 41, 47, 36, 41, 48, 32, 46,  1, 46, 30, 45, 32, 28, 40, 36,\n         41, 34,  9,  0, 12,  1,  8, 38, 28, 45, 43, 42, 49,  1]),\n 1147310)"},"metadata":{}}]},{"cell_type":"code","source":"n = int(0.9 * len(data))\ntrain = data[:n]\nval = data[n:]\nlen(train), len(val)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.621103Z","iopub.execute_input":"2024-08-18T17:55:24.621374Z","iopub.status.idle":"2024-08-18T17:55:24.628313Z","shell.execute_reply.started":"2024-08-18T17:55:24.621352Z","shell.execute_reply":"2024-08-18T17:55:24.627374Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"(1032579, 114731)"},"metadata":{}}]},{"cell_type":"code","source":"def split(type):\n    data = train if type == 'train' else val\n    idx = torch.randint(len(data) - block_size, (batch_size, ))\n    X = torch.stack([data[i: i + block_size] for i in idx])\n    y = torch.stack([data[i + 1: i + block_size + 1] for i in idx])\n    X, y = X.to(device), y.to(device)\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.629489Z","iopub.execute_input":"2024-08-18T17:55:24.629794Z","iopub.status.idle":"2024-08-18T17:55:24.638788Z","shell.execute_reply.started":"2024-08-18T17:55:24.629761Z","shell.execute_reply":"2024-08-18T17:55:24.638005Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"batch_size = 64 \nblock_size = 256 \nmax_iters = 3000\neval_interval = 500\nlearning_rate = 1e-3\neval_iters = 200\nn_embd = 384\nn_head = 6\nn_layer = 6\ndropout = 0.2","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.640116Z","iopub.execute_input":"2024-08-18T17:55:24.640687Z","iopub.status.idle":"2024-08-18T17:55:24.651355Z","shell.execute_reply.started":"2024-08-18T17:55:24.640663Z","shell.execute_reply":"2024-08-18T17:55:24.650458Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"Xtr, ytr = split('train')\nXtr.shape, ytr.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.652404Z","iopub.execute_input":"2024-08-18T17:55:24.652707Z","iopub.status.idle":"2024-08-18T17:55:24.666518Z","shell.execute_reply.started":"2024-08-18T17:55:24.652684Z","shell.execute_reply":"2024-08-18T17:55:24.665592Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"(torch.Size([64, 256]), torch.Size([64, 256]))"},"metadata":{}}]},{"cell_type":"markdown","source":"# Define Error List","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.667581Z","iopub.execute_input":"2024-08-18T17:55:24.667928Z","iopub.status.idle":"2024-08-18T17:55:24.672672Z","shell.execute_reply.started":"2024-08-18T17:55:24.667901Z","shell.execute_reply":"2024-08-18T17:55:24.671772Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for splits in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = split(splits)\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[splits] = losses.mean()\n    model.train()\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.673605Z","iopub.execute_input":"2024-08-18T17:55:24.673923Z","iopub.status.idle":"2024-08-18T17:55:24.683122Z","shell.execute_reply.started":"2024-08-18T17:55:24.673900Z","shell.execute_reply":"2024-08-18T17:55:24.682271Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        self.key = nn.Linear(n_embd, head_size, bias=False)\n        self.query = nn.Linear(n_embd, head_size, bias=False)\n        self.value = nn.Linear(n_embd, head_size, bias=False)\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        B,T,C = x.shape\n        k = self.key(x)   # (B,T,C)\n        q = self.query(x) # (B,T,C)\n        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n        wei = F.softmax(wei, dim=-1) # (B, T, T)\n        wei = self.dropout(wei)\n        v = self.value(x) # (B,T,C)\n        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.684235Z","iopub.execute_input":"2024-08-18T17:55:24.685097Z","iopub.status.idle":"2024-08-18T17:55:24.697989Z","shell.execute_reply.started":"2024-08-18T17:55:24.685066Z","shell.execute_reply":"2024-08-18T17:55:24.697212Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.proj = nn.Linear(n_embd, n_embd)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.699104Z","iopub.execute_input":"2024-08-18T17:55:24.699437Z","iopub.status.idle":"2024-08-18T17:55:24.708225Z","shell.execute_reply.started":"2024-08-18T17:55:24.699406Z","shell.execute_reply":"2024-08-18T17:55:24.707452Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class FeedFoward(nn.Module):\n    def __init__(self, n_embd):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_embd, 4 * n_embd),\n            nn.ReLU(),\n            nn.Linear(4 * n_embd, n_embd),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.709137Z","iopub.execute_input":"2024-08-18T17:55:24.709393Z","iopub.status.idle":"2024-08-18T17:55:24.719133Z","shell.execute_reply.started":"2024-08-18T17:55:24.709371Z","shell.execute_reply":"2024-08-18T17:55:24.718196Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, n_embd, n_head):\n        super().__init__()\n        head_size = n_embd // n_head\n        self.sa = MultiHeadAttention(n_head, head_size)\n        self.ffwd = FeedFoward(n_embd)\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n\n    def forward(self, x):\n        x = x + self.sa(self.ln1(x))\n        x = x + self.ffwd(self.ln2(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.720209Z","iopub.execute_input":"2024-08-18T17:55:24.721023Z","iopub.status.idle":"2024-08-18T17:55:24.729975Z","shell.execute_reply.started":"2024-08-18T17:55:24.720992Z","shell.execute_reply":"2024-08-18T17:55:24.729026Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"class BigramLanguageModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n        self.lm_head = nn.Linear(n_embd, vocab_size)\n\n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n        x = tok_emb + pos_emb # (B,T,C)\n        x = self.blocks(x) # (B,T,C)\n        x = self.ln_f(x) # (B,T,C)\n        logits = self.lm_head(x) # (B,T,vocab_size)\n\n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        for _ in range(max_new_tokens):\n            idx_cond = idx[:, -block_size:]\n#             print(self(idx_cond))\n#             print(\"idx_cond\", idx_cond)\n            logits, loss = self(idx_cond)\n            \n            logits = logits[:, -1, :] # becomes (B, C)\n            \n            probs = F.softmax(logits, dim=-1) # (B, C)\n#             print(\"probs\", probs)\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.731102Z","iopub.execute_input":"2024-08-18T17:55:24.731362Z","iopub.status.idle":"2024-08-18T17:55:24.745558Z","shell.execute_reply.started":"2024-08-18T17:55:24.731340Z","shell.execute_reply":"2024-08-18T17:55:24.744781Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"model = BigramLanguageModel()\nm = model.to(device)\nprint(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.746685Z","iopub.execute_input":"2024-08-18T17:55:24.746991Z","iopub.status.idle":"2024-08-18T17:55:24.897431Z","shell.execute_reply.started":"2024-08-18T17:55:24.746967Z","shell.execute_reply":"2024-08-18T17:55:24.896536Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"10.80354 M parameters\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n\nfor iter in range(max_iters):\n    if iter % eval_interval == 0 or iter == max_iters - 1:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n    xb, yb = split('train')\n    logits, loss = model(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T17:55:24.901106Z","iopub.execute_input":"2024-08-18T17:55:24.901396Z","iopub.status.idle":"2024-08-18T18:13:16.338410Z","shell.execute_reply.started":"2024-08-18T17:55:24.901373Z","shell.execute_reply":"2024-08-18T18:13:16.337321Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"step 0: train loss 4.5963, val loss 4.5919\nstep 500: train loss 1.6895, val loss 1.6713\nstep 1000: train loss 1.3401, val loss 1.3864\nstep 1500: train loss 1.2079, val loss 1.3137\nstep 2000: train loss 1.1157, val loss 1.2830\nstep 2500: train loss 1.0494, val loss 1.2786\nstep 2999: train loss 0.9871, val loss 1.2815\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Generate Text","metadata":{}},{"cell_type":"code","source":"def generate(num_words):\n    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n    print(text_processor.decode(m.generate(context, max_new_tokens = num_words)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:13:16.339840Z","iopub.execute_input":"2024-08-18T18:13:16.340189Z","iopub.status.idle":"2024-08-18T18:13:16.346258Z","shell.execute_reply.started":"2024-08-18T18:13:16.340153Z","shell.execute_reply":"2024-08-18T18:13:16.345261Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"generate(1000)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:13:16.347885Z","iopub.execute_input":"2024-08-18T18:13:16.348251Z","iopub.status.idle":"2024-08-18T18:13:32.389990Z","shell.execute_reply.started":"2024-08-18T18:13:16.348221Z","shell.execute_reply":"2024-08-18T18:13:32.389041Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"\n(JARVING) Backs.\nKILLIAN: David Chine fair!\nWe can get to out here!\nSir?\nWow.\n(DOWLING)\nThat ain't\n(GROANING)\nYou've been in but he way in two minutes.\nI come to base my chick.\nFrity, Cap. If he comes to him a monster...\nI can take this.\n(PEOPLE SCREETING)\n(SCREAMING) Is they divenored now?\nCome on.\n(HYMANATONE GRUNTS)\nTONY: No!\nDon't hurt National Selvignmerge. Is it a number operation?\nI'm not jusing...\nYou're impressed like you at the monster?\nDo you say? It's just a transfer, Rail.\n- This is doing. - Wait, a Wait!\nStark, what are we doing?\nI'm not surrounding.\nI can't affee, you can felt that if we can say\nlike you you talk get to the Stark Industries\n Vanition.\nComes off!\nWait, you know, you need to gain.\nI just saw just sitting facility.\nThe matter of the costume that is mybed, and it.\nIs this now takes?\nWell, yet Bender!\nWell, not be flaking down,\nyou steal to through the plant.\nI'm gonna her to be out, a long with a place has love.\nAnd been some with one of her that Two?\nIt's n\n","output_type":"stream"}]},{"cell_type":"code","source":"model_save_path = 'bigram_language_model.pth'\ntorch.save(model.state_dict(), model_save_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:16:37.627613Z","iopub.execute_input":"2024-08-18T18:16:37.628493Z","iopub.status.idle":"2024-08-18T18:16:37.725768Z","shell.execute_reply.started":"2024-08-18T18:16:37.628457Z","shell.execute_reply":"2024-08-18T18:16:37.725003Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}